{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tech\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM, LlamaTokenizerFast\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>\n",
      "LlamaTokenizer(name_or_path='G:\\code\\pretrain_model_dir\\llama-7b-hf', vocab_size=32000, model_max_length=1e+30, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True)}, clean_up_tokenization_spaces=False)\n"
     ]
    }
   ],
   "source": [
    "model_path = r\"G:\\code\\pretrain_model_dir\\llama-7b-hf\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_path)\n",
    "print(type(tokenizer))\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 这个分词器有点特殊, 没有定义这两个 token\n",
    "print(tokenizer.bos_token_id)\n",
    "print(tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用这个加载会有个 RecursionError, 不知道为啥\n",
    "# AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 33/33 [00:20<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16 cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    model_path, torch_dtype=torch.float16, device_map='auto',\n",
    ")\n",
    "print(model.dtype, model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"_name_or_path\": \"G:\\\\code\\\\pretrain_model_dir\\\\llama-7b-hf\",\n",
       "  \"architectures\": [\n",
       "    \"LLaMAForCausalLM\"\n",
       "  ],\n",
       "  \"bos_token_id\": 0,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 4096,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 11008,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"max_sequence_length\": 2048,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"num_key_value_heads\": 32,\n",
       "  \"pad_token_id\": -1,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"rms_norm_eps\": 1e-06,\n",
       "  \"rope_scaling\": null,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"float16\",\n",
       "  \"transformers_version\": \"4.32.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32000\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"_from_model_config\": true,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"pad_token_id\": -1,\n",
       "  \"transformers_version\": \"4.32.1\"\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tech\\Anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\generation\\utils.py:1411: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I look forward to the next 10 years.\\nI am a 20 year old female who has been diagnosed with PCOS. I have been on Metformin for 2 years and have']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这个推理速度很快, 比那个 3b-v2 的快多了. 显存占用 16 GB多\n",
    "prompt = \"I look forward to\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=40)\n",
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I love beijing , because it is a very beautiful city , and it is very interesting , and it is very beautiful , and it is very interesting , and it is very beautiful , and it is very interesting , and it is']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"I love beijing , because\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=40)\n",
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试推理速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: He opened his eyes and gaspe\n",
      ", time: 1.3360176086425781\n",
      "[\"He opened his eyes and gaspe\\nI'm not sure if this is the right place to post this, but I'm going to try. I'm a 20 year old male, and I've been having\"]\n",
      "query: She ran as fast as she coul\n",
      ", time: 1.2339355945587158\n",
      "['She ran as fast as she coul\\nd. She ran as fast as she could.\\ne. She ran as fast as she could.\\nf. She ran as fast as she could.\\ng. She ran as fast as']\n",
      "query: The phone rang. He ignored i\n",
      ", time: 1.173738956451416\n",
      "['The phone rang. He ignored i\\nt. He was in the middle of a very important project. He was working on a new invention. He was going to make a lot of money. He was going to be famous. He']\n",
      "query: They met at the airpor\n",
      ", time: 1.168050765991211\n",
      "['They met at the airpor\\nTheir love story began at the airport.\\nThe couple met at the airport in 2015.\\nThe couple met at the airport in 2015.']\n",
      "query: She loved him. He didn’t kno\n",
      ", time: 1.2172560691833496\n",
      "['She loved him. He didn’t kno\\nw. He didn’t know. He didn’t know. He didn’t know. He didn’t know. He didn’t know. He didn’t know. He didn']\n",
      "query: He had a secret. A big on\n",
      ", time: 1.1400370597839355\n",
      "['He had a secret. A big on\\ne. He was a spy.\\nf. He was a spy.\\ng. He was a spy.\\nh. He was a spy.\\ni. He was']\n",
      "query: She hated her job. But she staye\n",
      ", time: 1.1196434497833252\n",
      "['She hated her job. But she staye\\nd because she had to. She hated her boss. But she stayed because she had to. She hated her co-workers. But she stayed because she had to. She h']\n",
      "query: The door slammed. He was gon\n",
      ", time: 1.1838765144348145\n",
      "['The door slammed. He was gon\\nThe door slammed. He was gone.\\nI was alone in the house.\\nI was alone in the house. I was alone in the house. I was alone in the house. I']\n",
      "query: They found the treasure. And the tra\n",
      ", time: 1.1195006370544434\n",
      "['They found the treasure. And the tra\\n\\nComment: @JimmyShelter I\\'m not sure what you mean by \"the tra\".\\n\\nComment: @JimmyShelter I\\'m not sure what you mean']\n",
      "query: He was the last one aliv\n",
      ", time: 1.1654722690582275\n",
      "[\"He was the last one aliv\\nI'm not sure if this is the right place to post this, but I'm going to try.\\nI'm not sure if this is the right place to post this, but\"]\n",
      "query: She woke up in a strange place\n",
      ", time: 1.1791877746582031\n",
      "['She woke up in a strange place\\nShe woke up in a strange place\\nShe woke up in a strange place.\\nShe woke up in a strange place. She woke up in a strange place. She woke']\n",
      "query: He had a plan. A brilliant one\n",
      ", time: 1.1784489154815674\n",
      "['He had a plan. A brilliant one\\nI’m not sure what I’m doing here. I’m not sure what I’m doing with my life. I’m not sure what I’m doing with my faith.']\n",
      "query: The letter changed everything\n",
      ", time: 1.189232349395752\n",
      "['The letter changed everything\\nThe letter changed everything\\nThe letter changed everything\\nThe letter changed everything.\\nThe letter changed everything.\\nThe letter changed everything.\\nThe letter changed everything.\\nThe letter changed everything.\\n']\n",
      "query: She saw him and smiled\n",
      ", time: 1.1724116802215576\n",
      "['She saw him and smiled\\nShe saw him and smiled\\nHe saw her and smiled\\nHe saw her and smiled\\nShe saw him and smiled\\nShe saw him and smiled\\nHe saw her and smiled\\nHe saw her and']\n",
      "query: He was late. Again\n",
      ", time: 1.188511610031128\n",
      "['He was late. Again\\nHe was late. Again\\nHe was late. Again.\\nHe was late. Again.\\nHe was late. Again.\\nHe was late. Again.\\nHe was late. Again.']\n",
      "query: They were trapped. No escape\n",
      ", time: 1.1601417064666748\n",
      "['They were trapped. No escape\\nTheir eyes met.\\nTheir eyes met.\\nTheir eyes met.\\nTheir eyes met.\\nTheir eyes met.\\nTheir eyes met.\\nTheir eyes met']\n",
      "query: She couldn’t believe her eyes\n",
      ", time: 2.9461185932159424\n",
      "['She couldn’t believe her eyes\\nShe was so happy, she couldn’t believe her eyes\\nShe was so happy, she couldn’t believe her eyes.\\nShe was so happy, she couldn’t believe her eyes.']\n",
      "query: He heard a scream. He ran\n",
      ", time: 3.0691635608673096\n",
      "['He heard a scream. He ran\\nto the room where the scream came from. He saw a man\\nholding a woman. The man was trying to rape the woman.\\nThe man was a rapist. The man']\n",
      "query: They kissed. Fireworks exploded\n",
      ", time: 3.0333902835845947\n",
      "['They kissed. Fireworks exploded\\nin the sky. The crowd cheered.\\nThe couple walked down the aisle.\\nThe bride and groom kissed.\\nThe crowd cheered.\\nThe bride and']\n",
      "query: She had a choice. A hard one\n",
      ", time: 3.0739245414733887\n",
      "['She had a choice. A hard one\\nShe had a choice. A hard one\\nShe had a choice. A hard one.\\nShe had a choice. A hard one. She had a choice. A hard one. She had a']\n",
      "query: He had always wanted to fly\n",
      ", time: 3.134521484375\n",
      "['He had always wanted to fly\\nI was a little girl when I first saw him. He was a man in a uniform, a man who was a hero. He was a man who had always wanted to fly. He was a']\n",
      "query: She was the best detective in town\n",
      ", time: 3.1003670692443848\n",
      "['She was the best detective in town\\nShe was the best detective in town\\nShe was the best detective in town.\\nShe was the best detective in town.\\nShe was the best detective in town.\\nShe']\n",
      "query: The war was over. But not for him\n",
      ", time: 3.1053757667541504\n",
      "['The war was over. But not for him\\nThe war was over. But not for him\\nThe war was over. But not for him.\\nThe war was over. But not for him. He was a soldier, a veteran,']\n",
      "query: She had a gift. A dangerous one\n",
      ", time: 3.1098248958587646\n",
      "['She had a gift. A dangerous one\\nShe had a gift. A dangerous one\\nShe had a gift. A dangerous one.\\nShe had a gift. A dangerous one. She had a gift. A dangerous one. She had a']\n",
      "query: He didn’t expect to find love\n",
      ", time: 3.171983480453491\n",
      "['He didn’t expect to find love\\nI’m not sure if I’m going to be able to write this review without crying. I’m not sure if I’m going to be able to write this review without cry']\n",
      "query: She was lost in the woods\n",
      ", time: 3.1864285469055176\n",
      "['She was lost in the woods\\nShe was lost in the woods\\nShe was lost in the woods.\\nShe was lost in the woods.\\nShe was lost in the woods.\\nShe was lost in the woods.\\nShe']\n",
      "query: The virus was spreading. Fast\n",
      ", time: 3.133470058441162\n",
      "['The virus was spreading. Fast\\nThe virus was spreading. Fast\\nThe virus was spreading. Fast.\\nThe virus was spreading. Fast.\\nThe virus was spreading. Fast.\\nThe virus was spreading']\n",
      "query: He had a mission. A secret one\n",
      ", time: 3.179213285446167\n",
      "['He had a mission. A secret one\\nthat He had to keep.\\nHe was the Son of God.\\nHe was the Son of Man.\\nHe was the Son of David.\\nHe was the Son of Abraham.\\nHe']\n",
      "query: She was a princess. But not by choice\n",
      ", time: 3.1013667583465576\n",
      "['She was a princess. But not by choice\\nShe was a princess. But not by choice\\nShe was a princess. But not by choice.\\nShe was a princess. But not by choice. She was a princess.']\n",
      "query: He was a thief. A master one\n",
      ", time: 3.1295392513275146\n",
      "['He was a thief. A master one\\nat that. He had stolen from the rich and given to the poor.\\nHe had stolen from the powerful and given to the weak. He had\\nstolen from the corrupt and']\n",
      "[1.3360176086425781, 1.2339355945587158, 1.173738956451416, 1.168050765991211, 1.2172560691833496, 1.1400370597839355, 1.1196434497833252, 1.1838765144348145, 1.1195006370544434, 1.1654722690582275, 1.1791877746582031, 1.1784489154815674, 1.189232349395752, 1.1724116802215576, 1.188511610031128, 1.1601417064666748, 2.9461185932159424, 3.0691635608673096, 3.0333902835845947, 3.0739245414733887, 3.134521484375, 3.1003670692443848, 3.1053757667541504, 3.1098248958587646, 3.171983480453491, 3.1864285469055176, 3.133470058441162, 3.179213285446167, 3.1013667583465576, 3.1295392513275146]\n",
      "[40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40]\n",
      "每秒 token 数: 19.23072283742367\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 记录每次生成的时间和 token 数量\n",
    "time_list = []\n",
    "token_list = []\n",
    "\n",
    "query_list = [\n",
    "    \"I look forward to\",\n",
    "    \"I love beijing , because\",\n",
    "]\n",
    "with open(\"./data/query.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    query_list = f.readlines()\n",
    "\n",
    "for query in query_list:\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\").to(model.device)\n",
    "    start = time.time()\n",
    "    outputs = model.generate(**inputs, max_new_tokens=40)\n",
    "    end = time.time()\n",
    "    print(f\"query: {query}, time: {end - start}\")\n",
    "    print(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
    "\n",
    "    time_list.append(end - start)\n",
    "    token_list.append(outputs.shape[1] - inputs.input_ids.shape[1])\n",
    "\n",
    "print(time_list)\n",
    "print(token_list)\n",
    "# 计算每秒生成的 token 数量\n",
    "print(\"每秒 token 数:\", sum(token_list) / sum(time_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

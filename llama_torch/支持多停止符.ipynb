{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 我想要实现的是流式解码的时候支持多个停止符, 就是支持列表形式, 可以是字符串或者是 token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #模型下载\n",
    "# from modelscope import snapshot_download\n",
    "# model_dir = snapshot_download('qwen/Qwen1.5-0.5B-Chat')\n",
    "# print(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2TokenizerFast(name_or_path='D:\\code\\pretrained_model\\modelscope\\hub\\qwen\\Qwen1___5-0___5B-Chat', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|endoftext|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载下 qwen 的分词器\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "model_dir = r\"D:\\code\\pretrained_model\\modelscope\\hub\\qwen\\Qwen1___5-0___5B-Chat\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda', index=0), torch.float16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.device, model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "prompt = \"你是谁\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    model_inputs.input_ids,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "我是来自阿里云的大规模语言模型，我叫通义千问。我能够回答问题、创作文字，还能表达观点、撰写代码。有什么我可以帮助你的吗？\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer.encode(response)))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 我需要实现一个函数, 在模型流式输出的时候, 支持多个停止符, 停止符可以是字符串或者是数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "[104198, 31935, 64559, 99320, 56007, 11, 54851, 101919, 102661, 99718, 9370, 71304, 105483, 102064, 104949]\n",
      "我是 104198\n",
      "通 31935\n",
      "义 64559\n",
      "千 99320\n",
      "问 56007\n",
      ", 11\n",
      " 是 54851\n",
      "来自 101919\n",
      "阿里 102661\n",
      "云 99718\n",
      "的 9370\n",
      "超 71304\n",
      "大规模 105483\n",
      "语言 102064\n",
      "模型 104949\n"
     ]
    }
   ],
   "source": [
    "output_ids = tokenizer.encode(\"我是通义千问, 是来自阿里云的超大规模语言模型\")\n",
    "print(len(output_ids))\n",
    "print(output_ids)\n",
    "\n",
    "for output_id in output_ids:\n",
    "    print(tokenizer.decode(output_id), output_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我是', '通', '义', '千', '问', ',', ' 是', '来自', '阿里', '云', '的', '超', '大规模', '语言', '模型']\n"
     ]
    }
   ],
   "source": [
    "output_chunk_list = [tokenizer.decode(output_id) for output_id in output_ids]\n",
    "print(output_chunk_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env:\n",
    "    \"\"\"用来保存解码过程中的临时变量, 解码是流式解码, 每次给一个 output_id\"\"\"\n",
    "    def __init__(self):\n",
    "        # 保存先前未输出的文本\n",
    "        self.previous = \"\"\n",
    "        # 当前收到的 id 对应的文本\n",
    "        self.current = \"\"\n",
    "        # 是否停止\n",
    "        self.stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_one(output_id: int, env: Env, stop_list: list[int|str]):\n",
    "    \"\"\"解码一个 output_id, 这里只考虑 stop_list 为文本的情况\"\"\"\n",
    "    stop_str_list = [x for x in stop_list if isinstance(x, str) and len(x) > 0]\n",
    "    # 将当前 id 解码成文本. TODO: 没有考虑多个 id 对应一个文本的情况\n",
    "    current = tokenizer.decode(output_id)\n",
    "    \n",
    "    # 先拼接上历史的文本\n",
    "    current = env.previous + current\n",
    "\n",
    "    # 检查是否可能有停止符\n",
    "    # 什么情况下是安全的, 可以直接输出 current\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是\n",
      "通\n",
      "义\n",
      "千\n",
      "问\n",
      ",\n",
      " 是\n",
      "来自\n",
      "阿里\n",
      "云\n",
      "的\n",
      "超\n",
      "大规模\n",
      "语言\n",
      "模型\n"
     ]
    }
   ],
   "source": [
    "def check_stop_symbols(stream, stop_symbols):\n",
    "    for word in stream:\n",
    "        if any(symbol in word for symbol in stop_symbols):\n",
    "            break\n",
    "        yield word\n",
    "\n",
    "# 使用方法：\n",
    "stream = ['我是', '通', '义', '千', '问', ',', ' 是', '来自', '阿里', '云', '的', '超', '大规模', '语言', '模型']\n",
    "stop_symbols = ['通义']\n",
    "for chunk in check_stop_symbols(stream, stop_symbols):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是 \n",
      "通\n",
      "--遇到了结尾匹配的 义千\n"
     ]
    }
   ],
   "source": [
    "# TODO: 感觉有些复杂, 也不知道实现的对不对, 这是我和 bing 的混合结果\n",
    "# 定义输入和停止符列表\n",
    "input = ['我是', '通', '义', '千', '问', ',', ' 是', '来自', '阿里', '云', '的', '超', '大规模', '语言', '模型']\n",
    "stop_words = ['通1义', \"义千\"]\n",
    "\n",
    "# 定义一个函数，用于在流式输出的字符串中检查是否遇到了停止符\n",
    "def check_stop_words(input, stop_words):\n",
    "  # 初始化一个空字符串，用于存储输出\n",
    "  output = \"\"\n",
    "  # 初始化一个空字符串，用于存储当前的候选停止符\n",
    "  candidate = \"\"\n",
    "  # 遍历输入的字符串列表\n",
    "  for word in input:\n",
    "    if word in stop_words:\n",
    "        output += candidate\n",
    "        if output:\n",
    "            yield output\n",
    "        output = \"\"\n",
    "        print(\"==遇到停止符\", word)\n",
    "        break\n",
    "    # 如果当前的候选停止符不为空，就将当前的字符串添加到候选停止符中\n",
    "    if candidate:\n",
    "      candidate += word\n",
    "    # 如果当前的字符串是停止符列表中的第一个字符，就将当前的字符串作为候选停止符\n",
    "    elif word in [s[0] for s in stop_words]:\n",
    "      candidate = word\n",
    "    # 否则，将当前的字符串添加到输出中，并加上一个空格\n",
    "    else:\n",
    "      output += word + \" \"\n",
    "      yield output\n",
    "      output = \"\"\n",
    "    # 如果当前的候选停止符是停止符列表中的一个，就停止输出，并返回结果\n",
    "    if candidate in stop_words:\n",
    "      print(\"==遇到停止符\", candidate)\n",
    "      break\n",
    "    # 还有可能是结尾匹配的\n",
    "    for stop_word in stop_words:\n",
    "        if candidate.endswith(stop_word):\n",
    "            output += candidate[:-len(stop_word)]\n",
    "            candidate = \"\"\n",
    "            yield output\n",
    "            print(\"--遇到了结尾匹配的\", stop_word)\n",
    "            return\n",
    "    # 注意, 虽然第一个字符串在停止符列表中, 但是它不是停止符, 所以需要将它加回来\n",
    "    if candidate and len(candidate) >= max(map(len, stop_words)) and candidate not in stop_words:\n",
    "      print(\"--遇到了无法匹配的\", candidate)\n",
    "      output += candidate\n",
    "      candidate = \"\"\n",
    "\n",
    "  # 返回输出\n",
    "#   return output\n",
    "\n",
    "# 调用函数，并打印结果\n",
    "for  x in check_stop_words(input, stop_words):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现一个python算法, 在流式输出的字符串中检查是否遇到了停止符列表, 如果遇到了, 就停止输出, 停止符是字符串, 可能有多个字符组成, 也可能是单个字符.\n",
    "比如输入是 ['我是', '通', '义', '千', '问', ',', ' 是', '来自', '阿里', '云', '的', '超', '大规模', '语言', '模型'], 停止符列表是 ['通义'].\n",
    "这时候就应该只输出 \"我是\", 因为后面遇到了 \"通义\" 这个停止符. 不能只判断当前字符是否是停止符, 因为可能停止符是多个字符组成的."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

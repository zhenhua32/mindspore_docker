---
license: other
language:
- zh
- en
---
# BlueLM

<p align="center">
ğŸ–¥ <a href="https://github.com/vivo-ai-lab/BlueLM" target="_blank">github</a>  â€¢ ğŸ“œ <a href="https://huggingface.co/vivo-ai/BlueLM-7B-Chat/blob/main/MODEL_LICENSE" target="_blank">LICENSE</a> â€¢ ğŸ¯ <a href="https://developers.vivo.com/product/ai/bluelm" target="_blank">vivo Developers</a> â€¢ ğŸ—¨ <a href="https://github.com/vivo-ai-lab/BlueLM/blob/main/resources/wechat.png" target="_blank">WeChat</a>
</p>

## æ¨¡å‹ä»‹ç»/Introduction

BlueLM æ˜¯ç”± vivo AI å…¨çƒç ”ç©¶é™¢è‡ªä¸»ç ”å‘çš„å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œæœ¬æ¬¡å‘å¸ƒåŒ…å« 7B åŸºç¡€æ¨¡å‹å’Œ 7B å¯¹è¯æ¨¡å‹ï¼ŒåŒæ—¶æˆ‘ä»¬å¼€æºäº†æ”¯æŒ **32K** çš„é•¿æ–‡æœ¬åŸºç¡€æ¨¡å‹å’Œå¯¹è¯æ¨¡å‹ã€‚

- **æ›´å¤§é‡çš„ä¼˜è´¨æ•°æ®**ï¼šé«˜è´¨é‡è¯­æ–™åº“è¿›è¡Œè®­ç»ƒï¼Œè§„æ¨¡è¾¾åˆ°äº† **2.6 ä¸‡äº¿** çš„ token æ•°ï¼Œè¯¥è¯­æ–™åº“åŒ…å«ä¸­æ–‡ã€è‹±æ–‡ä»¥åŠå°‘é‡æ—¥éŸ©æ•°æ®ã€‚
- **æ›´ä¼˜çš„æ•ˆæœ**ï¼šå…¶ä¸­ BlueLM-7B-Chat åœ¨ **C-Eval** å’Œ **CMMLU** ä¸Šå‡å–å¾—é¢†å…ˆç»“æœï¼Œå¯¹æ¯”åŒå°ºå¯¸å¼€æºæ¨¡å‹ä¸­å…·æœ‰è¾ƒå¼ºçš„ç«äº‰åŠ›ã€‚
- **é•¿æ–‡æœ¬æ”¯æŒ**ï¼šBlueLM-7B-Base-32K å’Œ BlueLM-7B-Chat-32K å‡æ”¯æŒ **32K** é•¿æ–‡æœ¬ï¼Œåœ¨ä¿æŒåŸºç¡€èƒ½åŠ›ç›¸å½“æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿæ”¯æŒæ›´é•¿ä¸Šä¸‹æ–‡ç†è§£ã€‚
- **åè®®è¯´æ˜**ï¼šBlueLM ç³»åˆ—æ¬¢è¿å¼€å‘è€…è¿›è¡Œå­¦æœ¯ç ”ç©¶å’Œå•†ä¸šåº”ç”¨ã€‚

BlueLM is a large-scale open-source language model independently developed by the vivo AI Lab. This release includes 2K and 32K context length versions for both Base and Chat models.

- **High-quality Data**: BlueLM is trained on a high-quality data with 2.6 trillion tokens. Our train corpus mainly consists of Chinese and English data, with a small amount of Japanese and Korean data.
- **Stronger Performance**: BlueLM-7B-Chat achieves a strong competitive performance in C-Eval and CMMLU benchmarks of the same size.
- **Longer Context**: We have extended the context length of both BlueLM-7B-Base-32K and BlueLM-7B-Chat-32K models from 2K to 32K. The models can support longer context understanding while maintaining the same basic capabilities.
- **Model License**: BlueLM weights are open for academic research and commercial use. 

æœ¬æ¬¡å‘å¸ƒåŸºåº§æ¨¡å‹ä¸‹è½½é“¾æ¥è§ï¼š

The release versions and hugging face download links are listed in the table below:

|     |          Base Model        |          Chat Model        |       4bits Quantized Chat Model        |
|:---:|:--------------------:|:--------------------:|:--------------------------:|
| 7B-2k  | [BlueLM-7B-Base](https://huggingface.co/vivo-ai/BlueLM-7B-Base)  | [BlueLM-7B-Chat](https://huggingface.co/vivo-ai/BlueLM-7B-Chat)  | [BlueLM-7B-Chat-4bits](https://huggingface.co/vivo-ai/BlueLM-7B-Chat-4bits)  |
| 7B-32K | [BlueLM-7B-Base-32K](https://huggingface.co/vivo-ai/BlueLM-7B-Base-32K) | [BlueLM-7B-Chat-32K](https://huggingface.co/vivo-ai/BlueLM-7B-Chat-32K) | - |

## è¯„æµ‹ç»“æœ/Benchmark Results

ä¸ºäº†ä¿è¯æ¨¡å‹è¯„æµ‹çš„ä¸€è‡´æ€§ï¼Œæˆ‘ä»¬é‡‡ç”¨ [OpenCompass](https://opencompass.org.cn/leaderboard-llm) è¿›è¡Œç›¸å…³æ¦œå•çš„è¯„æµ‹ã€‚æˆ‘ä»¬åˆ†åˆ«åœ¨ C-Evalã€MMLUã€CMMLUã€GaoKaoã€AGIEvalã€BBHã€GSM8Kã€MATH å’Œ HumanEval æ¦œå•å¯¹ BlueLM çš„é€šç”¨èƒ½åŠ›ã€æ•°å­¦èƒ½åŠ›å’Œä»£ç èƒ½åŠ›è¿›è¡Œäº†æµ‹è¯•ã€‚

To ensure the consistency of model evaluation, we use [OpenCompass](https://opencompass.org.cn/leaderboard-llm) to evaluate the performance on relevant leaderboards. We conducted extensive tests on C-Eval, MMLU, CMMLU, GaoKao, AGIEval, BBH, GSM8K, MATH and HumanEval datasets across general ability, mathematical ability and coding ability.

| Model             | **C-Eval** | **MMLU** | **CMMLU** | **Gaokao** | **AGIEval** | **BBH** | **GSM8K** | **MATH** | **HumanEval** |
|:------------------|:-----------|:---------|:----------|:-----------|:------------|:--------|:----------|:---------|:--------------|
|                   | 5-shot     | 5-shot   | 5-shot    | 0-shot     | 0-shot      | 3-shot  | 4-shot    | 5-shot   | 0-shot        |
| GPT-4             | 69.9       | 86.4     | 71.2      | 72.3       | 55.1        | 86.7    | 91.4      | 45.8     | 74.4          |
| ChatGPT           | 52.5       | 70.0     | 53.9      | 51.1       | 39.9        | 70.1    | 78.2      | 28       | 73.2          |
| LLaMA2-7B         | 32.5       | 45.3     | 31.8      | 18.9       | 21.8        | 38.2    | 16.7      | 3.3      | 12.8          |
| ChatGLM2-6B(Base) | 51.7       | 47.9     | 50.0      | -          | -           | 33.7    | 32.4      | 6.5      | -             |
| Baichuan2-7B      | 56.3       | 54.7     | 57.0      | 34.8       | 34.6        | 41.8    | 24.6      | 5.4      | 17.7          |
| BlueLM-7B-Base    | 67.5       | 55.2     | 66.6      | 58.9       | 43.4        | 41.7    | 27.2      | 6.2      | 18.3          |
| BlueLM-7B-Chat    | 72.7       | 50.7     | 74.2      | 48.7       | 43.4        | 65.6    | 51.9      | 13.4     | 21.3          |

## æ¨ç†éƒ¨ç½²/Inference and Deployment

```python
>>> import torch
>>> from transformers import AutoModelForCausalLM, AutoTokenizer
>>> tokenizer = AutoTokenizer.from_pretrained("vivo-ai/BlueLM-7B-Chat", trust_remote_code=True, use_fast=False)
>>> model = AutoModelForCausalLM.from_pretrained("vivo-ai/BlueLM-7B-Chat", device_map="cuda:0", torch_dtype=torch.bfloat16, trust_remote_code=True)
>>> model = model.eval()
>>> inputs = tokenizer("[|Human|]:ä¸‰å›½æ¼”ä¹‰çš„ä½œè€…æ˜¯è°ï¼Ÿ[|AI|]:", return_tensors="pt")
>>> inputs = inputs.to("cuda:0")
>>> pred = model.generate(**inputs, max_new_tokens=64, repetition_penalty=1.1)
>>> print(tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))
ä¸‰å›½æ¼”ä¹‰çš„ä½œè€…æ˜¯è°ï¼Ÿ ã€Šä¸‰å›½æ¼”ä¹‰ã€‹æ˜¯å…ƒæœ«æ˜åˆå°è¯´å®¶ç½—è´¯ä¸­åˆ›ä½œçš„é•¿ç¯‡å°è¯´ã€‚
```

æ›´å¤šä½¿ç”¨è¯´æ˜ï¼Œè¯·å‚è€ƒæˆ‘ä»¬çš„ [Github ä»“åº“](https://github.com/vivo-ai-lab/BlueLM)ã€‚

For more instructions, please refer to our [Github Repo](https://github.com/vivo-ai-lab/BlueLM).

## åè®®/License

ç¤¾åŒºä½¿ç”¨ä»£ç ä¾ç…§ [Apache-2.0](https://www.apache.org/licenses/LICENSE-2.0) åè®®å¼€æºï¼Œä¸”ä½¿ç”¨ BlueLM æ¨¡å‹æƒé‡éœ€è¦éµå¾ª [vivo_BlueLMæ¨¡å‹è®¸å¯åè®®](https://huggingface.co/vivo-ai/BlueLM-7B-Chat/blob/main/MODEL_LICENSE)ã€‚

Our code is licensed under the [Apache-2.0](https://www.apache.org/licenses/LICENSE-2.0) and [Community License for BlueLM Model](https://huggingface.co/vivo-ai/BlueLM-7B-Chat/blob/main/MODEL_LICENSE).